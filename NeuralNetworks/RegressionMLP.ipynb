{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "from tensorflow import keras\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\",\"regressionmlp\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLP on California Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load, split and scale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 740us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure california_learning_curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"california_learning_curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From learning curves, we can see the model is good. In fact, the validation loss is less than training loss. This happens because regularisation is applied during training but not during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38856643],\n",
       "       [1.6792021 ],\n",
       "       [3.1022797 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning it is not converged and if we train it for more longer the model will perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have used sequential API. Let's use Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the neural network as shown in the figure called as Wide & Deep neural network on california housing dataset.\n",
    "<img src=\"images/widedeepnn.png\" width = 500 height = 500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.3996\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.3964\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4072\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.3986\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.3877\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.3887\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4156\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.4781\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4086 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3834\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3804\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4708\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3753\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.3716\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3971 - val_loss: 0.4041\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3697\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.3673\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3706\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4171\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3894 - val_loss: 0.3636\n",
      "162/162 [==============================] - 0s 761us/step - loss: 0.3932\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose what if we want to send different subsets of input features through the wide or deep paths? Let's send 5 features through wide path(featuers 0 to 4), and 6 through deep path(featuers 2 t0 7). Note than 3 features wil go through both (features 2,3,4)\n",
    "<img src=\"images/multipledeep.png\" width = 500 height = 500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
    "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation = \"relu\")(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation = \"relu\")(hidden_1)\n",
    "concat = keras.layers.concatenate([input_A, hidden_2])\n",
    "output = keras.layers.Dense(1, name = \"output\")(concat)\n",
    "model = keras.models.Model(inputs = [input_A, input_B], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8145 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6771 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5584 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4462 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 659us/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add auxillay output for regularisation as shown in the figure below.\n",
    "<img src = \"images/auxi.png\" width = 500, height = 500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
    "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation = \"relu\")(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation = \"relu\")(hidden_1)\n",
    "concat = keras.layers.concatenate([input_A, hidden_2])\n",
    "output = keras.layers.Dense(1, name = \"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name = \"aux_output\")(hidden_2)\n",
    "model = keras.models.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1365 - main_output_loss: 1.9196 - aux_output_loss: 4.0890 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8905 - main_output_loss: 0.6969 - aux_output_loss: 2.6326 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7429 - main_output_loss: 0.6088 - aux_output_loss: 1.9499 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6771 - main_output_loss: 0.5691 - aux_output_loss: 1.6485 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6381 - main_output_loss: 0.5434 - aux_output_loss: 1.4911 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6079 - main_output_loss: 0.5207 - aux_output_loss: 1.3923 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - main_output_loss: 0.5040 - aux_output_loss: 1.3175 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5666 - main_output_loss: 0.4898 - aux_output_loss: 1.2572 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5504 - main_output_loss: 0.4771 - aux_output_loss: 1.2101 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5373 - main_output_loss: 0.4671 - aux_output_loss: 1.1695 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5266 - main_output_loss: 0.4591 - aux_output_loss: 1.1344 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5173 - main_output_loss: 0.4520 - aux_output_loss: 1.1048 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5095 - main_output_loss: 0.4465 - aux_output_loss: 1.0765 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5027 - main_output_loss: 0.4417 - aux_output_loss: 1.0511 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4967 - main_output_loss: 0.4376 - aux_output_loss: 1.0280 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4916 - main_output_loss: 0.4343 - aux_output_loss: 1.0070 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4867 - main_output_loss: 0.4311 - aux_output_loss: 0.9872 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4829 - main_output_loss: 0.4289 - aux_output_loss: 0.9686 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4785 - main_output_loss: 0.4260 - aux_output_loss: 0.9510 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4756 - main_output_loss: 0.4246 - aux_output_loss: 0.9344 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 912us/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Subclassing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units = 30, activation = \"relu\", **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation = activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation = activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "model = WideAndDeepModel(30, activation = \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3298 - output_1_loss: 2.2186 - output_2_loss: 3.3304 - val_loss: 2.1435 - val_output_1_loss: 1.1581 - val_output_2_loss: 11.0117\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9714 - output_1_loss: 0.8543 - output_2_loss: 2.0252 - val_loss: 1.7567 - val_output_1_loss: 0.8205 - val_output_2_loss: 10.1825\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8268 - output_1_loss: 0.7289 - output_2_loss: 1.7082 - val_loss: 1.5664 - val_output_1_loss: 0.7913 - val_output_2_loss: 8.5419\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7636 - output_1_loss: 0.6764 - output_2_loss: 1.5477 - val_loss: 1.3088 - val_output_1_loss: 0.6549 - val_output_2_loss: 7.1933\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7211 - output_1_loss: 0.6402 - output_2_loss: 1.4489 - val_loss: 1.1357 - val_output_1_loss: 0.5964 - val_output_2_loss: 5.9898\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6895 - output_1_loss: 0.6124 - output_2_loss: 1.3833 - val_loss: 1.0036 - val_output_1_loss: 0.5937 - val_output_2_loss: 4.6933\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6632 - output_1_loss: 0.5894 - output_2_loss: 1.3274 - val_loss: 0.8904 - val_output_1_loss: 0.5591 - val_output_2_loss: 3.8714\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6410 - output_1_loss: 0.5701 - output_2_loss: 1.2796 - val_loss: 0.8009 - val_output_1_loss: 0.5243 - val_output_2_loss: 3.2903\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6204 - output_1_loss: 0.5514 - output_2_loss: 1.2416 - val_loss: 0.7357 - val_output_1_loss: 0.5144 - val_output_2_loss: 2.7275\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6024 - output_1_loss: 0.5355 - output_2_loss: 1.2043 - val_loss: 0.6849 - val_output_1_loss: 0.5014 - val_output_2_loss: 2.3370\n",
      "162/162 [==============================] - 0s 813us/step - loss: 0.5841 - output_1_loss: 0.5188 - output_2_loss: 1.1722\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_10_07-12_41_25'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/363 [..............................] - ETA: 2:30 - loss: 7.0195WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.419141). Check your callbacks.\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21324), started 0:01:02 ago. (Use '!kill 21324' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e5aa32c11c425d8d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e5aa32c11c425d8d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_10_07-12_46_08'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/363 [..............................] - ETA: 2:32 - loss: 5.0901WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.424197). Check your callbacks.\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5530 - val_loss: 302.8536\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 5292745216.0000 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3411 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3423 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3423 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3431 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3425 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3433 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3435 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3423 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3432 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3426 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3422 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3430 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3426 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3422 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3429 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3422 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3421 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3430 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3418 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3424 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3420 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3429 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3422 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3425 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3422 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3425 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3431 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3424 - val_loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Using tf.summary API we can visualize the scalars, histograms, images, texts, audio and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "        tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore number of hidden layers, number of neurons and learning rate for finding best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34988951683044434"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
